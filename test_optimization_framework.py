"""
===================================================================
SSVEP ä¼˜åŒ–æ¡†æ¶ - çœŸå®æ•°æ®æµ‹è¯•ä¸éªŒè¯
===================================================================

æœ¬è„šæœ¬æ¼”ç¤ºå¦‚ä½•ç”¨çœŸå®ç«èµ›æ•°æ®(D1, D2)æµ‹è¯•ä¼˜åŒ–ç®—æ³•
"""

import sys
import io
# è®¾ç½®UTF-8è¾“å‡ºç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import numpy as np
import pandas as pd
from pathlib import Path
import time
import warnings

warnings.filterwarnings('ignore')

from ssvep_optimization_framework import (
    OptimizedSSVEPClassifier,
    SSVEPEvaluator,
    ProductionSSVEPPipeline,
    DEFAULT_CONFIG,
    RobustPreprocessor,
)

# ===================================================================
# é…ç½®
# ===================================================================

DATA_DIR = Path(__file__).parent / "ExampleData"
OUTPUT_DIR = Path(__file__).parent / "optimization_results"
OUTPUT_DIR.mkdir(exist_ok=True)

FREQ_MAP = {
    0: 8.18, 1: 8.97, 2: 9.81, 3: 10.70,
    4: 11.64, 5: 12.62, 6: 13.65, 7: 14.71
}

# ===================================================================
# æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
# ===================================================================

class DataLoader:
    """åŠ è½½ç«èµ›D1/D2æ•°æ®"""
    
    @staticmethod
    def load_csv(csv_file, fs=250):
        """
        åŠ è½½CSVæ–‡ä»¶
        
        æ ¼å¼: [CP3, CPZ, CP4, PO3, POZ, PO4, taskID, stimID]
        å…±8åˆ—: 6ä¸ªEEGé€šé“ + taskID + stimID
        """
        df = pd.read_csv(csv_file)
        print(f"[Data] åŠ è½½ {csv_file.name}: shape={df.shape}")
        
        # æå–åˆ—
        eeg_cols = ['CP3', 'CPZ', 'CP4', 'PO3', 'POZ', 'PO4']
        eeg_data = df[eeg_cols].values  # [n_samples, 6_channels]
        
        # ä½¿ç”¨ stimID (ç›®æ ‡é¢‘ç‡æ ‡ç­¾) ä½œä¸ºåˆ†æ®µæ ‡ç­¾
        stim_ids = df['stimID'].values.astype(int)
        
        return eeg_data, stim_ids
    
    @staticmethod
    def segment_by_taskid(eeg_data, stim_ids, window_sec=4.0, fs=250):
        """
        æŒ‰ stimID åˆ†æ®µ
        
        å‚æ•°:
        -----
        eeg_data : ndarray, [n_samples, n_channels]
        stim_ids : ndarray, [n_samples]
            åˆºæ¿€ID (å¯¹åº”çš„é¢‘ç‡ç±»åˆ«)
        window_sec : float
            çª—å£é•¿åº¦ (ç§’)
        fs : float
            é‡‡æ ·ç‡
        
        è¿”å›:
        ------
        X : ndarray, [n_epochs, n_channels, n_samples]
            åˆ†æ®µçš„epochæ•°æ®
        y : ndarray, [n_epochs]
            å¯¹åº”çš„æ ‡ç­¾
        """
        window_samples = int(window_sec * fs)
        
        # æ‰¾å‡ºæ ‡ç­¾å˜åŒ–çš„åœ°æ–¹ (æ–°ä»»åŠ¡å—çš„å¼€å§‹)
        stim_changes = np.where(np.diff(stim_ids) != 0)[0] + 1
        boundaries = np.concatenate([[0], stim_changes, [len(stim_ids)]])
        
        X_list = []
        y_list = []
        
        for i in range(len(boundaries) - 1):
            start_idx = boundaries[i]
            end_idx = boundaries[i + 1]
            
            # å¦‚æœè¯¥å—è¶³å¤Ÿé•¿ï¼Œå¯ä»¥æå–å¤šä¸ªçª—å£
            segment_data = eeg_data[start_idx:end_idx]  # [seg_len, 6]
            stim_id = stim_ids[start_idx]
            
            # ä»è¯¥segmentä¸­æå–çª—å£ (çª—å£ä¸é‡å )
            n_windows = len(segment_data) // window_samples
            
            for j in range(n_windows):
                start = j * window_samples
                end = start + window_samples
                epoch = segment_data[start:end].T  # [6, window_samples]
                X_list.append(epoch)
                y_list.append(stim_id)
        
        X = np.array(X_list)
        y = np.array(y_list)
        
        print(f"[Data] åˆ†æ®µå®Œæˆ: {len(X)} epochs, å½¢çŠ¶ {X.shape}")
        print(f"[Data] æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(*np.unique(y, return_counts=True)))}")
        
        return X, y
    
    @staticmethod
    def load_and_segment(csv_file, window_sec=4.0, fs=250):
        """ä¸€ç«™å¼åŠ è½½ä¸åˆ†æ®µ"""
        eeg_data, task_ids = DataLoader.load_csv(csv_file, fs)
        X, y = DataLoader.segment_by_taskid(eeg_data, task_ids, window_sec, fs)
        return X, y


# ===================================================================
# æµ‹è¯•åœºæ™¯ 1: åŸºçº¿å¯¹æ¯”
# ===================================================================

def test_baseline_vs_optimized(X_train, y_train, X_test, y_test):
    """
    å¯¹æ¯”: åŸºçº¿CCA vs ä¼˜åŒ–ç®—æ³•
    """
    print("\n" + "="*70)
    print("åœºæ™¯1: åŸºçº¿CCA vs ä¼˜åŒ–ç®—æ³•å¯¹æ¯”")
    print("="*70)
    
    # é…ç½®1: åŸºçº¿ (ä»…CCA)
    config_baseline = DEFAULT_CONFIG.copy()
    config_baseline['use_fb_cca'] = False
    config_baseline['use_trca'] = False
    config_baseline['use_normalization'] = False
    
    # é…ç½®2: ä¼˜åŒ– (FB-CCA + TRCA + å½’ä¸€åŒ–)
    config_optimized = DEFAULT_CONFIG.copy()
    
    results = {}
    
    for name, config in [("åŸºçº¿CCA", config_baseline), ("ä¼˜åŒ–ç‰ˆæœ¬", config_optimized)]:
        print(f"\nğŸ“Š æµ‹è¯•: {name}")
        print("-" * 70)
        
        # è®­ç»ƒ
        start = time.time()
        model = OptimizedSSVEPClassifier(**config)
        model.fit(X_train, y_train)
        train_time = time.time() - start
        
        # é¢„æµ‹
        start = time.time()
        y_pred = model.predict(X_test)
        pred_time = time.time() - start
        
        # è¯„ä¼°
        acc = (y_pred == y_test).mean()
        from sklearn.metrics import confusion_matrix, recall_score, f1_score
        
        cm = confusion_matrix(y_test, y_pred)
        recall_per_class = cm.diagonal() / cm.sum(axis=1)
        recall_macro = recall_score(y_test, y_pred, average='macro')
        f1_macro = f1_score(y_test, y_pred, average='macro')
        
        results[name] = {
            'accuracy': acc,
            'recall_macro': recall_macro,
            'f1_macro': f1_macro,
            'recall_per_class': recall_per_class,
            'train_time': train_time,
            'pred_time_ms': pred_time * 1000 / len(X_test),
        }
        
        print(f"âœ“ å‡†ç¡®ç‡: {acc:.4f} ({int(acc*len(y_test))}/{len(y_test)})")
        print(f"âœ“ å®å¹³å‡å¬å›ç‡: {recall_macro:.4f}")
        print(f"âœ“ å®å¹³å‡F1: {f1_macro:.4f}")
        print(f"âœ“ æ¯ç±»å¬å›ç‡: {', '.join([f'{r:.2%}' for r in recall_per_class])}")
        print(f"âœ“ è®­ç»ƒè€—æ—¶: {train_time:.3f}s")
        print(f"âœ“ é¢„æµ‹å»¶è¿Ÿ: {results[name]['pred_time_ms']:.2f}ms/epoch")
    
    # æ”¹è¿›é‡
    acc_gain = (results["ä¼˜åŒ–ç‰ˆæœ¬"]["accuracy"] - results["åŸºçº¿CCA"]["accuracy"]) * 100
    print(f"\nğŸ¯ å‡†ç¡®ç‡æ”¹è¿›: +{acc_gain:.2f}pp (ç›¸å¯¹æå‡ {acc_gain/results['åŸºçº¿CCA']['accuracy']*100:.1f}%)")
    
    return results


# ===================================================================
# æµ‹è¯•åœºæ™¯ 2: äº¤å‰éªŒè¯
# ===================================================================

def test_cross_validation(X, y, k=5):
    """
    KæŠ˜äº¤å‰éªŒè¯è¯„ä¼°
    """
    print("\n" + "="*70)
    print(f"åœºæ™¯2: {k}æŠ˜äº¤å‰éªŒè¯è¯„ä¼°")
    print("="*70)
    
    config = DEFAULT_CONFIG.copy()
    
    results = SSVEPEvaluator.kfold_cv(X, y, OptimizedSSVEPClassifier, config, k=k)
    
    print("\nğŸ“ˆ äº¤å‰éªŒè¯ç»“æœæ±‡æ€»:")
    print(f"  å‡†ç¡®ç‡:    {results['accuracy_mean']:.4f} Â± {results['accuracy_std']:.4f}")
    print(f"  å¬å›ç‡:    {results['recall_mean']:.4f} Â± {results['recall_std']:.4f}")
    print(f"  F1-Score:  {results['f1_mean']:.4f} Â± {results['f1_std']:.4f}")
    
    return results


# ===================================================================
# æµ‹è¯•åœºæ™¯ 3: æ¶ˆèå®éªŒ
# ===================================================================

def test_ablation_study(X, y, k=5):
    """
    æ¶ˆèå®éªŒ: æµ‹è¯•å„ç»„ä»¶çš„è´¡çŒ®
    """
    print("\n" + "="*70)
    print("åœºæ™¯3: æ¶ˆèå®éªŒ (å„ç»„ä»¶è´¡çŒ®åº¦)")
    print("="*70)
    
    ablation_configs = {
        '1. åŸºçº¿ (ä»…CCA)': {
            'use_fb_cca': False, 'use_trca': False, 'use_normalization': False,
            'harmonics': 2
        },
        '2. + è§„èŒƒåŒ–': {
            'use_fb_cca': False, 'use_trca': False, 'use_normalization': True,
            'harmonics': 2
        },
        '3. + FB-CCA': {
            'use_fb_cca': True, 'use_trca': False, 'use_normalization': True,
            'harmonics': 2
        },
        '4. + TRCA': {
            'use_fb_cca': True, 'use_trca': True, 'use_normalization': True,
            'harmonics': 2
        },
        '5. + å¢å¼ºè°æ³¢': {
            'use_fb_cca': True, 'use_trca': True, 'use_normalization': True,
            'harmonics': 3
        },
    }
    
    ablation_results = {}
    
    print(f"\nè¿è¡Œ {len(ablation_configs)} ç§é…ç½®çš„ {k} æŠ˜äº¤å‰éªŒè¯...\n")
    
    for config_name, config_params in ablation_configs.items():
        # åˆå¹¶é…ç½®
        config = DEFAULT_CONFIG.copy()
        config.update(config_params)
        
        # è¿è¡ŒCV
        results = SSVEPEvaluator.kfold_cv(X, y, OptimizedSSVEPClassifier, config, k=k)
        ablation_results[config_name] = results
        
        acc = results['accuracy_mean']
        f1 = results['f1_mean']
        print(f"{config_name:25s} | Acc={acc:.4f} | F1={f1:.4f}")
    
    # è®¡ç®—å¢é‡
    baseline_acc = ablation_results['1. åŸºçº¿ (ä»…CCA)']['accuracy_mean']
    print(f"\nç›¸å¯¹åŸºçº¿çš„æ”¹è¿›:")
    for config_name, results in ablation_results.items():
        acc = results['accuracy_mean']
        improvement = (acc - baseline_acc) * 100
        print(f"  {config_name:25s}: +{improvement:5.2f}pp")
    
    return ablation_results


# ===================================================================
# æµ‹è¯•åœºæ™¯ 4: ç”Ÿäº§çº§éƒ¨ç½²
# ===================================================================

def test_production_pipeline(X_train, y_train, X_test, y_test):
    """
    ç”Ÿäº§çº§ç®¡é“æµ‹è¯•
    """
    print("\n" + "="*70)
    print("åœºæ™¯4: ç”Ÿäº§çº§éƒ¨ç½²ç®¡é“")
    print("="*70)
    
    # åˆ›å»ºç®¡é“
    pipeline = ProductionSSVEPPipeline(DEFAULT_CONFIG, latency_budget_ms=20)
    
    # è®­ç»ƒ
    print("\n[1] è®­ç»ƒç®¡é“...")
    pipeline.fit(X_train, y_train, validate=True)
    
    # é¢„æµ‹
    print("\n[2] æ‰¹é‡é¢„æµ‹...")
    y_pred, latencies = pipeline.predict_batch(X_test, return_latency=True)
    
    # è¯„ä¼°
    acc = (y_pred == y_test).mean()
    print(f"\n[3] è¯„ä¼°ç»“æœ:")
    print(f"  âœ“ å‡†ç¡®ç‡: {acc:.4f}")
    
    # æ€§èƒ½æŠ¥å‘Š
    perf = pipeline.get_performance_report()
    print(f"\n[4] å»¶è¿Ÿæ€§èƒ½:")
    if perf:
        print(f"  Mean:   {perf['mean_latency_ms']:.2f}ms")
        print(f"  Std:    {perf['std_latency_ms']:.2f}ms")
        print(f"  Min:    {perf['min_latency_ms']:.2f}ms")
        print(f"  Max:    {perf['max_latency_ms']:.2f}ms")
        print(f"  P95:    {perf['p95_latency_ms']:.2f}ms")
        print(f"  P99:    {perf['p99_latency_ms']:.2f}ms")
        print(f"  âœ“ æ»¡è¶³é¢„ç®—: {perf['meets_budget']}")
    else:
        print(f"  æ— å»¶è¿Ÿæ•°æ®")
    
    return pipeline, perf


# ===================================================================
# æµ‹è¯•åœºæ™¯ 5: å¼‚å¸¸å€¼ä¸é²æ£’æ€§
# ===================================================================

def test_robustness(X, y):
    """
    æµ‹è¯•é²æ£’æ€§: å¼‚å¸¸å€¼æ£€æµ‹, é€šé“åŠ æƒ
    """
    print("\n" + "="*70)
    print("åœºæ™¯5: é²æ£’æ€§æµ‹è¯•")
    print("="*70)
    
    # å¼‚å¸¸å€¼æ£€æµ‹
    print("\n[1] å¼‚å¸¸epochæ£€æµ‹...")
    outlier_mask = RobustPreprocessor.detect_outliers_mad(X, threshold=3.0)
    n_outliers = outlier_mask.sum()
    print(f"  æ£€æµ‹åˆ° {n_outliers} ä¸ªå¼‚å¸¸æ ·æœ¬ ({n_outliers/len(X)*100:.1f}%)")
    
    # æ¸…ç†
    X_clean = X[~outlier_mask]
    y_clean = y[~outlier_mask]
    
    # å¯¹æ¯”
    print(f"\n[2] æ¸…ç†å‰åå¯¹æ¯” (3æŠ˜CV):")
    
    results_dirty = SSVEPEvaluator.kfold_cv(X, y, OptimizedSSVEPClassifier, DEFAULT_CONFIG, k=3)
    results_clean = SSVEPEvaluator.kfold_cv(X_clean, y_clean, OptimizedSSVEPClassifier, DEFAULT_CONFIG, k=3)
    
    print(f"  æ¸…ç†å‰å‡†ç¡®ç‡: {results_dirty['accuracy_mean']:.4f}")
    print(f"  æ¸…ç†åå‡†ç¡®ç‡: {results_clean['accuracy_mean']:.4f}")
    improvement = (results_clean['accuracy_mean'] - results_dirty['accuracy_mean']) * 100
    print(f"  æ”¹è¿›: +{improvement:.2f}pp")
    
    # é€šé“åŠ æƒ
    print(f"\n[3] é€šé“é‡è¦æ€§åˆ†æ...")
    ch_weights = RobustPreprocessor.channel_weights_by_correlation(X_clean, y_clean)
    print(f"  é€šé“æƒé‡: {', '.join([f'Ch{i}={w:.2f}' for i, w in enumerate(ch_weights)])}")
    print(f"  æƒé‡æœ€é«˜çš„é€šé“: Ch{np.argmax(ch_weights)}")
    print(f"  æƒé‡æœ€ä½çš„é€šé“: Ch{np.argmin(ch_weights)}")


# ===================================================================
# ä¸»å‡½æ•°
# ===================================================================

def main():
    """å®Œæ•´æµ‹è¯•æµç¨‹"""
    
    print("\n")
    print("â•”" + "="*68 + "â•—")
    print("â•‘" + " "*15 + "SSVEP ä¼˜åŒ–æ¡†æ¶ - å®Œæ•´æµ‹è¯•" + " "*27 + "â•‘")
    print("â•š" + "="*68 + "â•")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # åŠ è½½æ•°æ®
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print("\nğŸ“¥ åŠ è½½æ•°æ®...")
    
    d1_file = DATA_DIR / "D1.csv"
    d2_file = DATA_DIR / "D2.csv"
    
    if not d1_file.exists() or not d2_file.exists():
        print(f"âš ï¸ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°! è¯·ç¡®ä¿åœ¨ {DATA_DIR}")
        print("   é¢„æœŸæ–‡ä»¶: D1.csv, D2.csv")
        return
    
    X_d1, y_d1 = DataLoader.load_and_segment(d1_file)
    X_d2, y_d2 = DataLoader.load_and_segment(d2_file)
    
    # åˆå¹¶æ•°æ®
    X_all = np.vstack([X_d1, X_d2])
    y_all = np.hstack([y_d1, y_d2])
    
    print(f"\nâœ“ æ€»æ•°æ®: {X_all.shape[0]} epochs, å½¢çŠ¶ {X_all.shape}")
    print(f"âœ“ ç±»åˆ«åˆ†å¸ƒ:\n{pd.Series(y_all).value_counts().sort_index()}")
    
    # åˆ†å‰² train/test
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X_all, y_all, test_size=0.2, stratify=y_all, random_state=42
    )
    
    print(f"\nâœ“ Train: {len(X_train)} epochs")
    print(f"âœ“ Test:  {len(X_test)} epochs")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # è¿è¡Œæµ‹è¯•åœºæ™¯
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # åœºæ™¯1: åŸºçº¿å¯¹æ¯”
    baseline_results = test_baseline_vs_optimized(X_train, y_train, X_test, y_test)
    
    # åœºæ™¯2: äº¤å‰éªŒè¯
    cv_results = test_cross_validation(X_all, y_all, k=5)
    
    # åœºæ™¯3: æ¶ˆèå®éªŒ
    ablation_results = test_ablation_study(X_all, y_all, k=3)
    
    # åœºæ™¯4: ç”Ÿäº§çº§ç®¡é“
    pipeline, perf = test_production_pipeline(X_train, y_train, X_test, y_test)
    
    # åœºæ™¯5: é²æ£’æ€§
    test_robustness(X_all, y_all)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ€»ç»“
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print("\n" + "="*70)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
    print("="*70)
    
    print("\nğŸ“Š å…³é”®æŒ‡æ ‡æ±‡æ€»:")
    print(f"  â€¢ åŸºçº¿å‡†ç¡®ç‡:        {baseline_results['åŸºçº¿CCA']['accuracy']:.4f}")
    print(f"  â€¢ ä¼˜åŒ–å‡†ç¡®ç‡:        {baseline_results['ä¼˜åŒ–ç‰ˆæœ¬']['accuracy']:.4f}")
    print(f"  â€¢ æ”¹è¿›:             +{(baseline_results['ä¼˜åŒ–ç‰ˆæœ¬']['accuracy']-baseline_results['åŸºçº¿CCA']['accuracy'])*100:.2f}pp")
    print(f"  â€¢ CVéªŒè¯å‡†ç¡®ç‡:      {cv_results['accuracy_mean']:.4f} Â± {cv_results['accuracy_std']:.4f}")
    if perf:
        print(f"  â€¢ å¹³å‡å»¶è¿Ÿ:         {perf['mean_latency_ms']:.2f}ms")
        print(f"  â€¢ æ˜¯å¦æ»¡è¶³é¢„ç®—(20ms): {perf['meets_budget']}")
    
    print("\nâœ¨ æ¡†æ¶ç‰¹æ€§:")
    print("  âœ“ Filter-Bank CCA (4å­å¸¦)")
    print("  âœ“ TRCAæ¨¡æ¿æ³•")
    print("  âœ“ RVå¾—åˆ†å½’ä¸€åŒ–")
    print("  âœ“ åæ–¹å·®æ”¶ç¼© (å¤‡é€‰)")
    print("  âœ“ KæŠ˜äº¤å‰éªŒè¯")
    print("  âœ“ ç”Ÿäº§çº§éƒ¨ç½²")


if __name__ == '__main__':
    main()
